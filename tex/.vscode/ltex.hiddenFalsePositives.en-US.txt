{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qhabil.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QVolker Rodehorst Master of Science Lucky Chandrautama\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QMultiple View 3D Avatar Style Transfer using Differential Rendering Prof. Dr.-Ing.\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_BEGINNING_RULE","sentence":"^\\QWhere I have quoted from the work of others, the source is always given.\\E$"}
{"rule":"WITH_THE_EXCEPTION_OF","sentence":"^\\QWith the exception of such quotations, this thesis is entirely my own work.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWith the increasing development of neural networks, researchers have been probing more intelligent and automatic algorithms for digital stylization with the self-learning ability in machine learning, as known as neural style transfer (NST) Gatys.2015.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QImplicit representations like Neural Radiance Fields (NeRFs) Mildenhall.2020 encapsulate volumetric characteristics and enable continuous and detailed modeling, albeit with slower optimization.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QHowever, meshes are not well suited for deformation and style transfer tasks due to their complex topology and diverse data structure Kang.2023.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QNeural Radiance Fields (NeRF) Mildenhall.2020 is a representation of a 3D scene that models the volumetric scene as a 5D vector-valued continuous function that maps 3D coordinates to radiance values.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QHowever, this can be leveraged by conversion to mesh or point cloud representation for example via Signed Distance Fields (SDF) conversion Darmon.2021 or the Marching Cubes algorithm Lorensen.1987\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWith 3D Gaussian Splatting Kerbl.2023, a scene is represented as a collection of many 3D Gaussians.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QWith sufficient density and overlap, a collection of 3D Gaussians can effectively visualize a surface reconstruction of a real-world object or scene with high accuracy.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QIn order to be able to support multiple styles in a single network, more advanced style transfer to enable multiple styles optimization emerges Varlamova.2022.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QBuilding upon Lora, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q propose a new framework called LyCORIs (Lora beYond Conventional methods, Other Rank adaptation Implementations) for diffusion-based models that collect and analyzes the various metrics and LoRa based fine-tuning methods specifically for text-to-image generative models.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QSome usages of CLIP include the computation of Text-to-Image Direction Similarity (CTIDS) and Image-Image Similarity (CIIS).\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QCLIP Text-Image Direction Similarity (CTIDS) measures how closely the semantic direction implied by a text prompt matches the direction between two images in CLIP's embedding space.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QCLIP Image-Image Similarity (CIIS) refers to the similarity between two images purely based on their visual content as encoded in CLIP's image embedding space.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QLPIPS is computed by comparing the perceptual features of two images using a pre-trained deep neural network, such as VGG or AlexNet, to measure the perceptual similarity between the images.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QAfterward, data preprocessing is done with Agisoft Metashape software to extract all the necessary data for the original 3D Gaussian Splatting.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qpipeline.model.continue-cull-post-densification=False pipeline.model.use-scale-regularization=True load-3D-points=True\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QIn order to perform style transfer on 3D avatars, it is necessary to consider both the geometry and the texture of the input avatar and the style guidance that can be expressed as a text prompt Nguyen-Phuoc.2023,Zhang.2023,Mendiratta.2023 or a reference image Han.2021,Abdal.2023,Zhang.2024,Jaganathan.2024.\\E$"}
